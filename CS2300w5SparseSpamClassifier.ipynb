{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 5: Sparse Spam Classification \n",
    "\n",
    "## Stuart Harley"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "This notebook provides an example of an app to classify phone SMS messages as either \"spam\" or \"ham\" (=not spam).  Some of this content has been adapted from a tutorial by Radimre Hurek:  https://radimrehurek.com/data_science_python/ and has been updated by Dr. Riley.  \n",
    "\n",
    "In this lab I am training a spam classifier using these text messages.  To do this I am modifying and extending a provided Jupyter Notebook that provides the fundamentals.  I am using a bag-of-words model as a sparse matrix representation of the messages and experimenting with the effect of the sparsity on the storage and performance.\n",
    "\n",
    "### Learning Outcomes\n",
    "- An understanding of the basics of training a model\n",
    "- Using a bag-of-words and TFIDF model in SKLearn\n",
    "- Adjusting sparsity to understand implications on model accuracy and performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/harleys/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/harleys/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to /home/harleys/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "from textblob import TextBlob\n",
    "import pandas\n",
    "import sklearn\n",
    "import nltk\n",
    "import sys\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Load data, explore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get the dataset and put it in the data folder.  ******** instructions to be updated********"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file contains **a collection of more than 5 thousand SMS phone messages** (see the `readme` file for more info).  First, load them using Pandas with one column named `label` and one named `message`..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     label                                            message\n",
      "0      ham  Go until jurong point, crazy.. Available only ...\n",
      "1      ham                      Ok lar... Joking wif u oni...\n",
      "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3      ham  U dun say so early hor... U c already then say...\n",
      "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
      "...    ...                                                ...\n",
      "5569  spam  This is the 2nd time we have tried 2 contact u...\n",
      "5570   ham               Will Ã¼ b going to esplanade fr home?\n",
      "5571   ham  Pity, * was in mood for that. So...any other s...\n",
      "5572   ham  The guy did some bitching but I acted like i'd...\n",
      "5573   ham                         Rofl. Its true to its name\n",
      "\n",
      "[5574 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "messages = pandas.read_csv('/data/cs2300/L5/SMSSpamCollection.txt', sep='\\t', quoting=csv.QUOTE_NONE,\n",
    "                           names=[\"label\", \"message\"])\n",
    "print(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should take a look at the basic statistics for this dataset using Pandas describe() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">message</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ham</th>\n",
       "      <td>4827</td>\n",
       "      <td>4518</td>\n",
       "      <td>Sorry, I'll call later</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spam</th>\n",
       "      <td>747</td>\n",
       "      <td>653</td>\n",
       "      <td>Please call our customer service representativ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      message                                                               \n",
       "        count unique                                                top freq\n",
       "label                                                                       \n",
       "ham      4827   4518                             Sorry, I'll call later   30\n",
       "spam      747    653  Please call our customer service representativ...    4"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages.groupby('label').describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "add a Pandas column that describes the length of the messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages[\"length\"] = messages[\"message\"].map(lambda message : len(message))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will allow you to run the cell below to make a histogram of the length.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fbb0d8a5da0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "messages.length.plot(bins=20, kind='hist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    5574.000000\n",
       "mean       80.478292\n",
       "std        59.848302\n",
       "min         2.000000\n",
       "25%        36.000000\n",
       "50%        62.000000\n",
       "75%       122.000000\n",
       "max       910.000000\n",
       "Name: length, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages.length.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find and print that really long one..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For me the love should start with attraction.i should feel that I need her every time around me.she should be the first thing which comes in my thoughts.I would start the day and end it with her.she should be there every time I dream.love will be then when my every breath has her name.my life should happen around her.my life will be named to her.I would cry for her.will give all my happiness and take all her sorrows.I will be ready to fight with anyone for her.I will be in love when I will be doing the craziest things for her.love will be when I don't have to proove anyone that my girl is the most beautiful lady on the whole planet.I will always be singing praises for her.love will be when I start up making chicken curry and end up makiing sambar.life will be the most beautiful then.will get every morning and thank god for the day because she is with me.I would like to say a lot..will tell later..\n"
     ]
    }
   ],
   "source": [
    "index = messages[\"length\"].idxmax()\n",
    "print(messages[\"message\"].iloc[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see if there is there any difference in message length between spam and ham by running the following code to plot them side by side. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([<matplotlib.axes._subplots.AxesSubplot object at 0x7fbb0cfc3898>,\n",
       "       <matplotlib.axes._subplots.AxesSubplot object at 0x7fbb0c598f98>],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEQCAYAAACqduMIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAbUElEQVR4nO3de7RdZXnv8e+PICiIhIQNQi7sKCmtVUG6BY6ettQIJOIwlCEVjpbIiSc9Q2jp0XMkaMdBbfWEntMiDCttJIFQ0XCxLbGJYIpSh5YgO1zCJUA2GMgmQDZNiFq8EHjOH/PdsLL3uy/rOtde+/cZY4295jvnWu+z9nrf+cx33pYiAjMzs6H2KTsAMzNrT04QZmaW5QRhZmZZThBmZpblBGFmZllOEGZmluUE0aYkbZX03rLjMLPJywnCzMyynCDMzCzLCaK9HSdpk6Tdkq6X9FpJh0j6Z0kDknal5zMHXyDpdkl/IenfJP1M0rckTZd0naSfSLpLUnd5H8lsfCRdJOkpST+V9IikeZI+K+mm1B9+KuluScdWvGappMfSvIck/X7FvI9K+qGkyyQ9L+lxSe9K5dsk7ZC0qJxP256cINrbHwDzgTnA24GPUnxnVwNHAbOBnwNfHvK6s4E/BGYAbwbuSK+ZBmwGLml+6Ga1k3QMcAHwzog4CDgN2JpmLwRupGjPXwf+SdJr0rzHgN8GDgY+B3xN0hEVb30isAmYnl67GngncDTwEeDLkl7fvE82sThBtLcrImJ7ROwEvgUcFxH/HhHfjIgXIuKnwBeA3x3yuqsj4rGI2A18G3gsIv4lIvZQdKx3tPRTmFXvJWB/4C2SXhMRWyPisTRvY0TcFBEvAn8NvBY4CSAibkx95uWIuB7YApxQ8b4/joirI+Il4HpgFvD5iPhlRHwH+BVFsjCcINrdMxXPXwBeL+kASX8n6QlJPwG+D0yVNKVi2Wcrnv88M+0tJGtrEdEH/CnwWWCHpNWSjkyzt1Us9zLQDxwJIOlcSfemXUjPA28FDq1466F9gYhw/xiBE8TE80ngGODEiHgD8DupXOWFZNZ4EfH1iPjPFLtTA7g0zZo1uIykfYCZwHZJRwFfpdg1NT0ipgIP4L5RMyeIiecgiq2c5yVNw8cTrANJOkbSeyTtD/yCos2/lGb/lqQzJe1LMcr4JbABOJAikQyk9ziPYgRhNXKCmHi+BLwOeI6iU9xSbjhmTbE/sIyinT8DHAZ8Os27GfgQsIviZIwzI+LFiHgI+CuKkzKeBd4G/LDFcXcU+QeDzGyikPRZ4OiI+EjZsUwGHkGYmVmWE4SZmWV5F5OZmWV5BGFmZllOEGZmlrVv2QGM5tBDD43u7u6yw7AOtHHjxucioqvsOKrh/mDNMFpfaOsE0d3dTW9vb9lhWAeS9ETZMVTL/cGaYbS+4F1MZmaW5QRhZmZZThBmZpblBGFmZllOEGZmluUEYWZmWU4QZmaW5QRhZmZZbX2h3Hh1L137yvOty04vMRIzmywG1zudvM7xCMLMzLKcIMwaQNJKSTskPZCZ9z8lhaRD07QkXSGpT9ImSce3PmKzsTlBmDXGNcD8oYWSZgGnAE9WFC8A5qbHEuDKFsRnVrUxE0SjtowkLZK0JT0WNfZjmJUrIr4P7MzMugz4FFD5y1wLgWujsAGYKumIFoRpVpXxjCCuoc4tI0nTgEuAE4ETgEskHVJP4GbtTtIHgKci4r4hs2YA2yqm+1OZWVsZM0E0aMvoNGB9ROyMiF3AejJJx6xTSDoA+Azwv3OzM2XZ3/6VtERSr6TegYGBRoZoNqaajkHUsGU07i0mdwjrEG8G5gD3SdoKzATulvRGivY/q2LZmcD23JtExPKI6ImInq6uCfX7RtYBqk4QNW4ZjXuLyR3COkFE3B8Rh0VEd0R0UySF4yPiGWANcG46ZncSsDsini4zXrOcWkYQtWwZjXuLyWwikvQN4A7gGEn9khaPsvg64HGgD/gq8PEWhGhWtaqvpI6I+4HDBqdTkuiJiOckrQEukLSa4oD07oh4WtKtwBcrDkyfClxcd/RmbSIizhljfnfF8wDOb3ZMZvUaz2mudW8ZRcRO4M+Bu9Lj86nMzMza1JgjiEZtGUXESmBllfGZmVlJfCW1mZllOUGYmVmWE4SZmWU5QZiZWZYThJmZZTlBmJlZlhOEmZllOUGYmVmWE4SZmWU5QZiZWZYThJmZZTlBmJlZlhOEmZllOUGYmVmWE4SZmWU5QZiZWZYThJmZZTlBmJlZlhOEWQNIWilph6QHKsr+r6SHJW2S9I+SplbMu1hSn6RHJJ1WTtRmoxszQTSq4Uuan8r6JC1t/EcxK9U1wPwhZeuBt0bE24FHgYsBJL0FOBv4zfSar0ia0rpQzcZnPCOIa6iz4afG/zfAAuAtwDlpWbOOEBHfB3YOKftOROxJkxuAmen5QmB1RPwyIn4M9AEntCxYs3EaM0E0qOGfAPRFxOMR8StgdVrWbLL4r8C30/MZwLaKef2pbBhJSyT1SuodGBhocohme2vEMYjxNPxxdwizTiPpM8Ae4LrBosxikXttRCyPiJ6I6Onq6mpWiGZZ+9bz4ioafi4RZTuEpCXAEoDZs2fXE55Z6SQtAt4PzIuIwTbfD8yqWGwmsL3VsZmNpeYRREXD//A4Gv64O4S3mKxTSJoPXAR8ICJeqJi1Bjhb0v6S5gBzgR+VEaPZaGpKEDU0/LuAuZLmSNqP4kD2mvpCN2sfkr4B3AEcI6lf0mLgy8BBwHpJ90r6W4CIeBC4AXgIuAU4PyJeKil0sxGNuYspNfyTgUMl9QOXUJy1tD9FwwfYEBH/PSIelDTY8PdQ0fAlXQDcCkwBVqZOYtYRIuKcTPGKUZb/AvCF5kVkVr8xE0SjGn5ErAPWVRWdmZmVxldSm5lZlhOEmZllOUGYmVmWE4SZmWU5QZiZWZYThJmZZTlBmJlZlhOEmZllOUGYmVmWE4SZmWU5QZiZWZYThJmZZdX1g0FmZpNJ99K1ZYfQUh5BmJlZlhOEmZllOUGYmVmWE4SZmWU5QZiZWZYThFkDSFopaYekByrKpklaL2lL+ntIKpekKyT1Sdok6fjyIjcb2ZgJolENX9KitPwWSYua83HMSnMNMH9I2VLgtoiYC9yWpgEWAHPTYwlwZYtiNKvKeEYQ11Bnw5c0DbgEOBE4AbhkMKmYdYKI+D6wc0jxQmBVer4KOKOi/NoobACmSjqiNZGajd+YCaJBDf80YH1E7IyIXcB6hicds05zeEQ8DZD+HpbKZwDbKpbrT2VmbaXWYxDVNnx3CLNXKVMW2QWlJZJ6JfUODAw0OSyzvTX6IPVIDd8dwiajZwd3HaW/O1J5PzCrYrmZwPbcG0TE8ojoiYierq6upgZrNlStCaLahu8OYZPRGmDwhIxFwM0V5eemkzpOAnYPjsjN2kmtCaLahn8rcKqkQ9LB6VNTWcN1L1076W6oZeWT9A3gDuAYSf2SFgPLgFMkbQFOSdMA64DHgT7gq8DHSwjZbExj3s01NfyTgUMl9VOcjbQMuCF1gieBs9Li64D3UTT8F4DzACJip6Q/B+5Ky30+IoYe+DabsCLinBFmzcssG8D5zY3IrH5jJohGNfyIWAmsrCo6MzMrja+kNjOzLCcIMzPLcoIwM7MsJwgzM8tygjAzsywnCDMzy3KCMDOzLCcIMzPLcoIwM7MsJwgzM8tygjAzsywnCDMzy3KCMDOzLCcIMzPLcoIwM7MsJwgzM8tygjAzsywnCDMzy3KCMDOzLCcIsyaT9D8kPSjpAUnfkPRaSXMk3Slpi6TrJe1XdpxmQ9WVIKpp+JL2T9N9aX53Iz6AWTuTNAP4E6AnIt4KTAHOBi4FLouIucAuYHF5UZrl1Zwgamj4i4FdEXE0cFlazmwy2Bd4naR9gQOAp4H3ADel+auAM0qKzWxE9e5iqqbhL0zTpPnzJKnO+s3aWkQ8Bfw/4EmK/rEb2Ag8HxF70mL9wIxyIjQbWc0JooaGPwPYll67Jy0/fej7SloiqVdS78DAQK3hmbUFSYdQbBzNAY4EDgQWZBaNEV7v/mClqWcXU7UNPzdaGNYpImJ5RPRERE9XV1et4Zm1i/cCP46IgYh4EfgH4F3A1DTyBpgJbM+92P3BylTPLqZqG34/MAsgzT8Y2FlH/WYTwZPASZIOSLtU5wEPAd8DPpiWWQTcXFJ8ZiOqJ0FU2/DXpGnS/O9GRHZYbdYpIuJOimNudwP3U/S55cBFwCck9VHsal1RWpBmI9h37EXyIuJOSYMNfw9wD0XDXwuslvQXqWyw4a8A/j51iJ0UZzyZdbyIuAS4ZEjx48AJJYRjNm41JwioruFHxC+As+qpz8zMWsdXUpuZWZYThJmZZTlBmJlZlhOEmZllOUGYmVmWE4SZmWXVdZqrmdlk17107SvPty47vcRIGs8jCDMzy3KCMDOzLCcIMzPLcoIwM7MsJwgzM8tygjAzsywnCDMzy3KCMDOzLCcIMzPLcoIwM7MsJwgzM8tygjBrMklTJd0k6WFJmyX9J0nTJK2XtCX9PaTsOM2GqitBVNPwVbhCUp+kTZKOb8xHMGt7lwO3RMSvA8cCm4GlwG0RMRe4LU2btZV6RxDVNPwFwNz0WAJcWWfdZm1P0huA3wFWAETEryLieWAhsCottgo4o5wIzUZWc4KooeEvBK6NwgZgqqQjao7cbGJ4EzAAXC3pHklXSToQODwingZIfw8rM0iznHp+D6Ky4R8LbAQuZEjDlzTY8GcA2ype35/Knq4jBrN2ty9wPPDHEXGnpMupYneSpCUUI25mz57dnAhtmE7+jYdq1LOLabDhXxkR7wD+g9EbvjJlMWwhaYmkXkm9AwMDdYRn1hb6gf6IuDNN30TRb54dHEGnvztyL46I5RHRExE9XV1dLQnYbFA9CaLaht8PzKp4/Uxg+9A3bVSH6F669pWHWVki4hlgm6RjUtE84CFgDbAolS0Cbi4hPLNR1Zwgamj4a4Bz09lMJwG7B3dFmXW4Pwauk7QJOA74IrAMOEXSFuCUNG3WVur9TerBhr8f8DhwHkXSuUHSYuBJ4Ky07DrgfUAf8EJa1qzjRcS9QE9m1rxWx2JWjboSRDUNPyICOL+e+szMrHV8JbWZmWU5QZiZWZYThJmZZTlBmJlZlhOEmZllOUGYmVmWE4SZmWU5QZiZWVa9V1KbmXW0yXw/N48gzMwsywnCzMyynCDMzCzLCcLMzLJ8kNrMLJnMB6RzPIIwM7MsJwgzM8vyLiYzm9S8W2lkHkGYmVmWE4SZmWXVnSAkTZF0j6R/TtNzJN0paYuk6yXtl8r3T9N9aX53vXWPV/fSta88zMow3n5i1k4aMYK4ENhcMX0pcFlEzAV2AYtT+WJgV0QcDVyWljObLMbbT8zaRl0JQtJM4HTgqjQt4D3ATWmRVcAZ6fnCNE2aPy8tb9bRquwnZm2j3hHEl4BPAS+n6enA8xGxJ033AzPS8xnANoA0f3da3qzTVdNPzNpGzQlC0vuBHRGxsbI4s2iMY17l+y6R1Cupd2BgoNbwzNpCDf1k6OvdH6w09Ywg3g18QNJWYDXFkPlLwFRJg9dXzAS2p+f9wCyANP9gYOfQN42I5RHRExE9XV1ddYRn1haq7Sd7cX+wMtWcICLi4oiYGRHdwNnAdyPiw8D3gA+mxRYBN6fna9I0af53IyK71WTWKWroJ2ZtoxnXQVwEfEJSH8W+1hWpfAUwPZV/AljahLrNJoqR+olZ22jIrTYi4nbg9vT8ceCEzDK/AM5qRH1mE9F4+olZO/GV1GZmluUEYWZmWU4QZmaW5QRhZmZZThBmZpblBGFmZllOEGZmluUEYWZmWU4QZmaW5QRhZmZZThBmZpblBGFmZlkNuVlfJ+leuvaV51uXnV5iJGZm5XKCMLNJp3JD0EbmXUxmZpY16UYQuS0H70oyMxvOIwgzM8tygjAzsywnCDMzy3KCMDOzrJoThKRZkr4nabOkByVdmMqnSVovaUv6e0gql6QrJPVJ2iTp+EZ9CLN2VW0/MWsn9ZzFtAf4ZETcLekgYKOk9cBHgdsiYpmkpcBS4CJgATA3PU4Erkx/S+dzoq2Jqu0nZm2j5gQREU8DT6fnP5W0GZgBLAROToutAm6naPgLgWsjIoANkqZKOiK9j1lHqqGfWAP4jgiN0ZBjEJK6gXcAdwKHD67009/D0mIzgG0VL+tPZUPfa4mkXkm9AwMDjQjPrC2Ms58MfY37g5Wm7gQh6fXAN4E/jYifjLZopiyGFUQsj4ieiOjp6uqqNzyztlBFP9mL+4OVqa4EIek1FI3+uoj4h1T8rKQj0vwjgB2pvB+YVfHymcD2euo3mwiq7CdmbaOes5gErAA2R8RfV8xaAyxKzxcBN1eUn5vOZjoJ2O3jD9bpaugnZm2jnrOY3g38IXC/pHtT2aeBZcANkhYDTwJnpXnrgPcBfcALwHl11G02UVTbT8zaRj1nMf2A/HEFgHmZ5QM4v9b6zCaiavuJWTuZsHdz9bULZmbN5VttmFlH61661huUNXKCMDOzLCcIM5twPCpojQl7DMLMOl8jb5nhhFI9jyDMzCzLCcLMzLK8i8nMOoJ3ITWeRxBmZpblEYSZTVgeNTSXE4SZNc1k++GeTvu8ThBmllXrym6srfpOW4l2Mh+DMDOzLCcIMzPL8i4mM2s7ud1UPiDdek4Qo/C+UjObzJwgzKwteITQfpwgzCaZwRVxI0fFXrkPl/ufTLQ9ET5IbWZmWS0fQUiaD1wOTAGuiohlrY6hFs3Y6rLJrZ36QlnH2ybzyGMiHONsaYKQNAX4G+AUoB+4S9KaiHiolXE0ykT4gq09tXNfGOsMolrb+mROBhNVq0cQJwB9EfE4gKTVwEKg9E4xXiM18lwHcgKxUTS0L4y18s21v1pX2F7R166a/129649GrH9anSBmANsqpvuBE1scQ9PVcg535RdYzRfrJDRhTYq+YBNbqxOEMmWx1wLSEmBJmvyZpEdGeK9DgecaGNt4NaVeXTpm+Zj1jvQedeqo/3OFo5r43uMxZl+AqvrD6JXV3zbKagftUn9TYxjr+0nza65/jPcfsS+0OkH0A7MqpmcC2ysXiIjlwPKx3khSb0T0NDa8sbnezq63hcbsCzD+/tBsZX8fZdffDjGUUX+rT3O9C5graY6k/YCzgTUtjsGsHbgvWNtr6QgiIvZIugC4leLUvpUR8WArYzBrB+4LNhG0/DqIiFgHrGvAW5U17Ha9nV1vyzSwL7RC2d9H2fVD+TG0vH5FDDsuZmZm5lttmJlZnhOEmZllTZi7uUr6dYorTWdQnC++HVgTEZtLDczMrENNiGMQki4CzgFWU5w/DsV542cDq5t9kzNJh1ORmCLi2WbWN6TuaUBExK4W1jmpPq9ZuyqzL8LESRCPAr8ZES8OKd8PeDAi5jap3uOAvwUOBp5KxTOB54GPR8TdTap3NvCXwLxUl4A3AN8FlkbE1ibVO6k+rw0n6WDgYuAMoCsV7wBuBpZFxPMtjKXclaMkintmVe61+FG0YKVZVl8cJiLa/gE8DByVKT8KeKSJ9d4LnJgpPwm4r4n13gF8CJhSUTaFYsS0wZ/XjyZ+F7cCFwFvrCh7Yypb36IYjgM2AJuBf0mPh1PZ8S2K4VSgD/g2cFV63JLKTm1B/aX0xaGPiTKCmA98GdjCqzc4mw0cDVwQEbc0qd4tMcLoRFJfRBxdQr0jzmtyvR33eW04SY9ExDHVzmtwDPcCfxQRdw4pPwn4u4g4tgUxbAYWxJDRq6Q5wLqI+I0m119KXxxqQhykjohbJP0arw73RLqHfkS81MSqvy1pLXAtryamWcC5FFsTzbJR0leAVUPqXQTc08R6J9vnteGekPQpYFWkXTppV89H2fvus8104NDkABARGyQd2KIY9uXV452VngJe04L6y+qLe5kQI4gySVrAq2dPDSamNVFcBdusOvcDFufqBVZExC+bWPek+ry2N0mHAEspvovDKfa9P0vxXVwaETtbEMMVwJvJrxx/HBEXtCCGi4E/oDgxpjKGs4EbIuL/tCCGlvfFYTE4QZjZSCT9NsXI/f6I+E4L6y1/5Sj9xggxTJgfOKuXE8QoKs7oWAgcloqbfkaHpH0ptqjPYO8zKG6m2KJ+cZSX11PvpPq8NpykH0XECen5x4DzgX+iOGj7rZggvyE/0ZXVF4fyldSjuwHYBfxeREyPiOnA71GcanZjE+v9e4ozOT4HvA84PT0/FvhaE+udbJ/Xhqvcv/5HFGfsfI4iQXy4FQFIOljSMkmbJf17emxOZVNbFMP8IfFcJWmTpK+nYzLNVlZf3ItHEKMo64yOMep9NCJ+rYR6O+7z2nCS7gNOpth4vDUqfqBG0j0R8Y4WxHArxTUwqyLimVT2RooD5fMi4pQWxHB3RByfnl8FPAN8FTgT+N2IOKPJ9Zd+Nhl4BDGWJyR9qnKLQdLh6cruZp7RsUvSWZJe+X4k7SPpQxRbFc0y2T6vDXcwsBHoBaalFTOSXk/+Z1KboTsiLh1MDgAR8UzavTW7RTFU6omIP4uIJyLiMqC7BXWW1Rf34gQxug8B04F/lbRL0k7gdmAaxRkOzXI28EHgWUmPStpCsQVzZprXLGV/3mfS532U1nxeGyIiuiPiTRExJ/0dXEm/DPx+i8Joh5XjYZI+IemTwBvSVdWDWrHeLKsv7sW7mMag4iaBMymu6P1ZRfn8Zl2gN6T+6RRbbl+KiI80ua4TgYcjYrekAyhOdzweeBD4YkTsblK9+1Hca2s7cDewAHhXqne5D1JPLkNOtR08QDt4qu2yaMF9uiRdMqToKxExkEZUfxkR57YghlLXPeAEMSpJf0JxFsdmioOoF0bEzWneK/som1Bv7reJ30OxX5aI+ECT6n0QODaKn8NcDvwH8E2KeyQdGxFnNqne6yguTHodsBs4EPjHVK8iYlEz6rWJR9J5EXF1p8dQ1rpnqAlxJXWJ/hvwWxHxM0ndwE2SuiPicpq7P3Ym8BDF/V8i1fVO4K+aWCfAPhGxJz3vqWiEP1Bx+4NmeVtEvD2d7voUcGREvCTpa8B9TazXJp7PAaUmiBbFUNa6Zy9OEKObMji0i4itkk6m+KKOorlfUg9wIfAZ4H9FxL2Sfh4R/9rEOgEeqNg6uk9ST0T0qrjNSTN38+yTdjMdCBxAcaB0J7A/rbmtgbURSZtGmkVxdfdkiKGsdc9enCBG94yk4yLiXoCUzd8PrATe1qxKI+Jl4DJJN6a/z9Ka7+pjwOWS/gx4DrhD0jaKA4Mfa2K9Kyju1jmFIineKOlxijtXrm5ivdaeDgdOY/gZbAL+bZLEUMq6ZygfgxiFpJnAnsrT7SrmvTsiftiiOE4H3h0Rn25RfQcBbyLdsCxacB9+SUcCRMT2dDHUe4EnI+JHza7b2oukFcDVEfGDzLyvR8R/6fQY2mbd4wRhZmY5vg7CzMyynCDMzCzLCcLMzLKcIMzMLMsJwszMsv4/K7ks+RuWYvIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "messages.hist(column='length', by='label', bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, but this is not sufficient for us to create a classifier.  We need machine learning!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we convert the raw messages (sequence of characters) into vectors (sequences of numbers).\n",
    "\n",
    "The mapping is not 1-to-1; we'll use the [bag-of-words](http://en.wikipedia.org/wiki/Bag-of-words_model) approach, where each unique word in a text will be represented by one number.\n",
    "\n",
    "As a first step, here is a function that will split a message into its individual words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_tokens(message):\n",
    "    return TextBlob(message).words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should tokenize them by applying the split_into_tokens method to the message column of the dataframe in the following cell.  Print the results to convince yourself that they are correct.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [Go, until, jurong, point, crazy, Available, o...\n",
       "1                       [Ok, lar, Joking, wif, u, oni]\n",
       "2    [Free, entry, in, 2, a, wkly, comp, to, win, F...\n",
       "3    [U, dun, say, so, early, hor, U, c, already, t...\n",
       "4    [Nah, I, do, n't, think, he, goes, to, usf, he...\n",
       "Name: message, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages[\"message\"].map(lambda message : split_into_tokens(message)).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With textblob, we can detect [part-of-speech (POS)](http://www.ling.upenn.edu/courses/Fall_2007/ling001/penn_treebank_pos.html) tags with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Hello', 'NNP'),\n",
       " ('world', 'NN'),\n",
       " ('how', 'WRB'),\n",
       " ('is', 'VBZ'),\n",
       " ('it', 'PRP'),\n",
       " ('going', 'VBG')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TextBlob(\"Hello world, how is it going?\").tags  # list of (word, POS) pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_lemmas(message):\n",
    "    words = TextBlob(message).words\n",
    "    # for each word, take its \"base form\" = lemma \n",
    "    return [word.lemma for word in words]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize words into their base form ([lemmas](http://en.wikipedia.org/wiki/Lemmatisation)) by applying the split_into_lemmas function below to the message column of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [Go, until, jurong, point, crazy, Available, o...\n",
       "1                       [Ok, lar, Joking, wif, u, oni]\n",
       "2    [Free, entry, in, 2, a, wkly, comp, to, win, F...\n",
       "3    [U, dun, say, so, early, hor, U, c, already, t...\n",
       "4    [Nah, I, do, n't, think, he, go, to, usf, he, ...\n",
       "Name: message, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages[\"message\"].head().map(lambda message : split_into_lemmas(message))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can probably think of many more ways to improve the preprocessing: decoding HTML entities (those `&amp;` and `&lt;` we saw above); filtering out stop words (pronouns etc); adding more features, such as an word-in-all-caps indicator and so on.  So keep those in mind for later..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Data to vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now need to convert each message, represented as a list of tokens (lemmas) above, into a vector that machine learning models can understand.\n",
    "\n",
    "Doing that requires essentially three steps, in the bag-of-words model:\n",
    "\n",
    "1. counting how many times does a word occur in each message (term frequency)\n",
    "2. weighting the counts, so that frequent tokens get lower weight (inverse document frequency)\n",
    "3. normalizing the vectors to unit length, to abstract from the original text length\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each vector has as many dimensions as there are unique words in the SMS corpus.  We can count the number of unique words using the following cell..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11010\n"
     ]
    }
   ],
   "source": [
    "bow_transformer = CountVectorizer(analyzer=split_into_lemmas).fit(messages['message'])\n",
    "print(len(bow_transformer.vocabulary_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we used `scikit-learn` (`sklearn`), a powerful Python library for teaching machine learning. It contains a multitude of various methods and options.\n",
    "\n",
    "Let's take one text message and get its bag-of-words counts as a vector, putting to use our new `bow_transformer`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U dun say so early hor... U c already then say...\n"
     ]
    }
   ],
   "source": [
    "message4 = messages['message'][3]\n",
    "print(message4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 4189)\t2\n",
      "  (0, 4762)\t1\n",
      "  (0, 5363)\t1\n",
      "  (0, 6219)\t1\n",
      "  (0, 6243)\t1\n",
      "  (0, 7137)\t1\n",
      "  (0, 9280)\t2\n",
      "  (0, 9589)\t1\n",
      "  (0, 10054)\t1\n",
      "(1, 11010)\n"
     ]
    }
   ],
   "source": [
    "bow4 = bow_transformer.transform([message4])\n",
    "print(bow4)\n",
    "print(bow4.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, nine unique words are in this message.  Two of them appear twice, the rest only once. \n",
    "\n",
    "Write some code in the next cell that identifies the words that appear twice.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U\n",
      "say\n"
     ]
    }
   ],
   "source": [
    "print(bow_transformer.get_feature_names()[4189])\n",
    "print(bow_transformer.get_feature_names()[9280])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bag-of-words counts for the entire SMS corpus are a large, sparse matrix.  In the following cell, calculate the sparsity from the number of non-zero elements (`messages_bow.nnz`) and the shape.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sparse matrix shape: (5574, 11010)\n",
      "non-zero messages: 81623\n",
      "sparsity: 0.13%\n"
     ]
    }
   ],
   "source": [
    "messages_bow = bow_transformer.transform(messages[\"message\"])\n",
    "print(\"sparse matrix shape:\", messages_bow.shape)\n",
    "print(\"non-zero messages:\", messages_bow.nnz)\n",
    "print(\"sparsity: %.2f%%\" % (100*messages_bow.nnz/(messages_bow.shape[0]*messages_bow.shape[1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, lets see what the bow array looks like if we convert it to a \"dense\" array and print it out.  Lots of 0s right?  We can calculate the storage required by using `sys.getsizeof(array)` so please add that call to the following cell.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "490958032\n"
     ]
    }
   ],
   "source": [
    "messages_array = messages_bow.toarray()\n",
    "print(messages_array)\n",
    "print(sys.getsizeof(messages_array))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Term weighting and normalization can be done with [TF-IDF](http://en.wikipedia.org/wiki/Tf%E2%80%93idf), using scikit-learn's `TfidfTransformer`, and we can apply it to the message we used above.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 10054)\t0.22510385070095637\n",
      "  (0, 9589)\t0.1955442748962185\n",
      "  (0, 9280)\t0.49597495370832545\n",
      "  (0, 7137)\t0.4269339327922034\n",
      "  (0, 6243)\t0.3100112284407115\n",
      "  (0, 6219)\t0.2913528957227454\n",
      "  (0, 5363)\t0.2860779240943588\n",
      "  (0, 4762)\t0.25892595706356525\n",
      "  (0, 4189)\t0.391088549792437\n"
     ]
    }
   ],
   "source": [
    "tfidf_transformer = TfidfTransformer().fit(messages_bow)\n",
    "tfidf4 = tfidf_transformer.transform(bow4)\n",
    "print(tfidf4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To transform the entire bag-of-words corpus into TF-IDF corpus at once:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5574, 11010)\n"
     ]
    }
   ],
   "source": [
    "messages_tfidf = tfidf_transformer.transform(messages_bow)\n",
    "print(messages_tfidf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Training a model, detecting spam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With messages represented as vectors, we can finally train our spam/ham classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be using scikit-learn here, choosing the [Naive Bayes](http://en.wikipedia.org/wiki/Naive_Bayes_classifier) classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_detector = MultinomialNB().fit(messages_tfidf, messages['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try classifying our single random message:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted: ham\n",
      "expected: ham\n"
     ]
    }
   ],
   "source": [
    "print('predicted:', spam_detector.predict(tfidf4)[0])\n",
    "print('expected:', messages.label[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hooray!\n",
    "\n",
    "A natural question is to ask, how many messages do we classify correctly overall?  The following cell will calculate this for us..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.9721923214926445\n"
     ]
    }
   ],
   "source": [
    "all_predictions = spam_detector.predict(messages_tfidf)\n",
    "print('accuracy', accuracy_score(messages['label'], all_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are quite a few possible metrics for evaluating model performance. Which one is the most suitable depends on the task. For example, the cost of mispredicting \"spam\" as \"ham\" is probably much lower than mispredicting \"ham\" as \"spam\".  Differences between errors can be illuminated using metrics other than accuracy, which we will discuss later.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Let's get realistic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above \"evaluation\", we committed a cardinal sin. For simplicity of demonstration, we evaluated accuracy on the same data we used for training. **Never evaluate on the same dataset you train on!**\n",
    "\n",
    "Such evaluation tells us nothing about the true predictive power of our model. If we simply remembered each example during training, the accuracy on training data would trivially be 100%, even though we wouldn't be able to classify any new messages.  This is exactly like memorizing the exact answers for an exam without understanding the underlying material!\n",
    "\n",
    "A proper way is to split the data into a training/test set, where the model only ever sees the **training data** during its model fitting and parameter tuning. The **test data** is never used in any way -- thanks to this process, we make sure we are not \"cheating\", and that our final evaluation on test data is representative of true predictive performance.\n",
    "\n",
    "The following code splits the dataset into a training and testing set.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4459 1115 5574\n"
     ]
    }
   ],
   "source": [
    "msg_train, msg_test, label_train, label_test = \\\n",
    "    train_test_split(messages['message'], messages['label'], test_size=0.2)\n",
    "\n",
    "print(len(msg_train), len(msg_test), len(msg_train) + len(msg_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, as requested, the test size is 20% of the entire dataset.\n",
    "\n",
    "Next, lets set up our split datasets to be ready to be used by the Bayes model for training and prediction..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_messages_bow = bow_transformer.transform(msg_train)\n",
    "train_tfidf_transformer = TfidfTransformer().fit(train_messages_bow)\n",
    "train_messages_tfidf = train_tfidf_transformer.transform(train_messages_bow)\n",
    "test_messages_bow = bow_transformer.transform(msg_test)\n",
    "test_tfidf_transformer = TfidfTransformer().fit(test_messages_bow)\n",
    "test_messages_tfidf = test_tfidf_transformer.transform(test_messages_bow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can train a new Naive Bayes classifier with only the training data, and test it with the test data, and our accuracy should drop.  In this cell answer: why?\n",
    "\n",
    "**Answer**: The training data is not as extensive as the full test data, so there are cases in the test data that the system incorrectly classified because it didn't experiance a case similar enough to that in the training data to correctly identify it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updated accuracy: 94.88789%\n"
     ]
    }
   ],
   "source": [
    "split_spam_detector = MultinomialNB().fit(train_messages_tfidf, label_train)\n",
    "test_predictions = split_spam_detector.predict(test_messages_tfidf)\n",
    "print('updated accuracy: %.5f%%' % (accuracy_score(label_test, test_predictions)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, re-run this experiment changing the test size to a different value (in the subsequent cells of this part) and develop an explanation for the results (it should be different than your accuracy value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code splits the dataset into a new training and testing set. In this case, the test size is 95% of the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "278 5296 5574\n"
     ]
    }
   ],
   "source": [
    "msg_train2, msg_test2, label_train2, label_test2 = \\\n",
    "    train_test_split(messages['message'], messages['label'], test_size=.95)\n",
    "\n",
    "print(len(msg_train2), len(msg_test2), len(msg_train2) + len(msg_test2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code set up our split datasets to be ready to be used by the Bayes model for training and prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_messages_bow2 = bow_transformer.transform(msg_train2)\n",
    "train_tfidf_transformer2 = TfidfTransformer().fit(train_messages_bow2)\n",
    "train_messages_tfidf2 = train_tfidf_transformer2.transform(train_messages_bow2)\n",
    "test_messages_bow2 = bow_transformer.transform(msg_test2)\n",
    "test_tfidf_transformer2 = TfidfTransformer().fit(test_messages_bow2)\n",
    "test_messages_tfidf2 = test_tfidf_transformer2.transform(test_messages_bow2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code runs the test data and determines the accuracy of the results. Since the test data is 95% of the entire dataset, it should be expected that the accuracy is lower."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updated accuracy: 86.59366%\n"
     ]
    }
   ],
   "source": [
    "split_spam_detector2 = MultinomialNB().fit(train_messages_tfidf2, label_train2)\n",
    "test_predictions2 = split_spam_detector2.predict(test_messages_tfidf2)\n",
    "print('updated accuracy: %.5f%%' % (accuracy_score(label_test2, test_predictions2)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Next Steps\n",
    "\n",
    "In the following cells you should make some changes to the dataset (cast to lowercase, remove numbers, remove non-words, add content, etc) to sufficiently change the sparsity percentage.  The number of columns in your bag of words model should be significantly smaller.  The goal of this is see the size comparison in the non-compressed version of the matrix (`toarray`) vs the sparse representation as the size of the data changes.  If we didn't have a sparse representation, our ability to use a BOW model would be very limiting...\n",
    "\n",
    "Run the experiments again to assess the accuracy of your new dataset and compare it with your previous results.  You should make arguments about what caused the changes and why they make sense.  Calculate and compare the storage requirements of the non-sparse and sparse representations, and argue how using sparse matricies can enable better accuracy.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cell is a function to clean a string. This means setting it to lower case and removing non-alphabetic characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(message):\n",
    "    lower = message.lower()\n",
    "    cleaned = ''\n",
    "    for letter in lower:\n",
    "        if letter.isalpha() or letter == \" \":\n",
    "            cleaned += letter\n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cell is a function to split a string by spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(string):\n",
    "    return string.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cell two new dataframe columns are created of cleaned messages and the length of the cleaned messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages[\"cleaned\"] = messages[\"message\"].map(lambda message : clean(message))\n",
    "messages[\"cleaned length\"] = messages[\"cleaned\"].map(lambda clean : len(clean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cell I create a new dictionary containing the unique words from the messages and the number of times they occur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = pd.DataFrame([elem for singleList in list(map(split, messages[\"cleaned\"])) for elem in singleList])\n",
    "all_words.columns = [\"words\"]\n",
    "unique = all_words[\"words\"].value_counts().to_frame()\n",
    "unique = unique.reset_index()\n",
    "unique.columns = [\"Word\", \"Occurances\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cell I identify the words in the bottom 25% of the previous dataframe. These are the words that are used the least in the messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_25 = int(unique.size*.25)\n",
    "uncommon_words = pd.DataFrame(unique[\"Word\"][-last_25:])\n",
    "uncommon_words.columns = [\"Word\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cell is a function to remove any word that occurs in the bottom 25% of the used words from a message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_rare_words(message):\n",
    "    message_words = message.split()\n",
    "    result_words = []\n",
    "    for word in message_words:\n",
    "        if word not in uncommon_words[\"Word\"].values:\n",
    "            result_words.append(word)\n",
    "    return ' '.join(result_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cell I create a new column in my original dataframe that contains the messages with the 25% least occurring words removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages[\"Common\"] = messages[\"cleaned\"].map(lambda message : remove_rare_words(message))\n",
    "messages[\"Common length\"] = messages[\"Common\"].map(lambda message : len(message))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this cell I count the number of unique words in the \"common\" messages. As shown the count is 4015, as opposed to 11010 before the messages were cleaned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4013\n"
     ]
    }
   ],
   "source": [
    "bow_transformer3 = CountVectorizer(analyzer=split_into_lemmas).fit(messages['Common'])\n",
    "print(len(bow_transformer3.vocabulary_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bag-of-words counts for the entire SMS corpus are a large, sparse matrix.  In the following cell, I calculate the sparsity from the number of non-zero elements and the shape. As shown in the cell, the sparsity is at .32% as opposed to .13% before the messages were cleaned. This change occured because I removed any non-alphabetic words and the least common words so the number of columns in the matrix was greatly reduced (from 11010 to 4013)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sparse matrix shape: (5574, 4013)\n",
      "non-zero messages: 71376\n",
      "sparsity: 0.32%\n"
     ]
    }
   ],
   "source": [
    "common_bow = bow_transformer3.transform(messages[\"Common\"])\n",
    "print(\"sparse matrix shape:\", common_bow.shape)\n",
    "print(\"non-zero messages:\", common_bow.nnz)\n",
    "print(\"sparsity: %.2f%%\" % (100*common_bow.nnz/(common_bow.shape[0]*common_bow.shape[1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this cell term weighting and normalization using scikit-learn's `TfidfTransformer` transforms the entire bag-of-words corpus into TF-IDF corpus at once:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5574, 4013)\n"
     ]
    }
   ],
   "source": [
    "tfidf_transformer3 = TfidfTransformer().fit(common_bow)\n",
    "common_tfidf = tfidf_transformer3.transform(common_bow)\n",
    "print(common_tfidf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code splits the dataset into a training and testing set that is 20% of the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4459 1115 5574\n"
     ]
    }
   ],
   "source": [
    "common_train, common_test, label_train, label_test = \\\n",
    "    train_test_split(messages['Common'], messages['label'], test_size=0.2)\n",
    "\n",
    "print(len(common_train), len(common_test), len(common_train) + len(common_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I set up our split datasets to be ready to be used by the Bayes model for training and prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_common_bow = bow_transformer3.transform(common_train)\n",
    "train_tfidf_transformer3 = TfidfTransformer().fit(train_common_bow)\n",
    "train_common_tfidf = train_tfidf_transformer3.transform(train_common_bow)\n",
    "test_common_bow = bow_transformer3.transform(common_test)\n",
    "test_tfidf_transformer3 = TfidfTransformer().fit(test_common_bow)\n",
    "test_common_tfidf = test_tfidf_transformer3.transform(test_common_bow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this cell we test the Naive Bayes classifier with the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updated accuracy: 96.41256%\n"
     ]
    }
   ],
   "source": [
    "split_spam_detector3 = MultinomialNB().fit(train_common_tfidf, label_train)\n",
    "test_predictions3 = split_spam_detector3.predict(test_common_tfidf)\n",
    "print('updated accuracy: %.5f%%' % (accuracy_score(label_test, test_predictions3)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this cell I compare the space requirements for the sparce and non-sparce representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bytes in sparse array: 490958032\n",
      "bytes in compressed sparse array: 571008\n"
     ]
    }
   ],
   "source": [
    "common_array = common_bow.toarray()\n",
    "print(\"bytes in sparse array: \" + str(sys.getsizeof(messages_array)))\n",
    "print(\"bytes in compressed sparse array: \" + str(common_tfidf.data.nbytes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "- After removing all non-alphabetic words, changing the messages to lowercase, and removing the 25% least common words from the messages, the accuracy of the classification went up from about 94% to about 96%. This makes sense because spam messages usually use the same words that are not commonly found in regular messages. i.e. invest, etc. Spam messages are also often spelled correctly, while regular texts will often use abbreviations and shorten the words. Therefore, while many of the words from the texts will have been removed, the spam messages will be relatively the same and the algorithm is still able to classify them appropriately.\n",
    "\n",
    "- The sparse array when not compressed takes up 490,958,032 bytes. The compressed version uses only 571,000. The compressed version takes up less storage than the non-compressed form because it is only storing the location of non-zero elements.\n",
    "\n",
    "- Sparse matrices improve accuracy because they allow for a unique form of storing data that stores both whether a something is contained in the data, but also if it is not. This allows for the data to be used to make comparisons between different values that are being stored in the matrix and in this lab we used it to predict whether or not messages were spam or ham for example."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
